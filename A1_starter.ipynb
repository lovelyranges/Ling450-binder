{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e97487",
   "metadata": {},
   "source": [
    "# Ling 450/807 SFU - Assignment 1\n",
    "\n",
    "This assignment walks you through two different ways of extracting simple quotes from text and then directs you to a third, already implemented way. Your task is to enhance the simple methods or develop your own. For further instructions, check the assignment file on Canvas. \n",
    "The binder contains this notebook and some sample files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab766cdc",
   "metadata": {},
   "source": [
    "Group 1: Antanila, Rachel, Lovely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd654f4",
   "metadata": {},
   "source": [
    "## Approach 1: Using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c548f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5207a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loads and processes only one file at a time. You need to do 5 and comment on the results\n",
    "# to load the 5 texts, you can just change the name of the file below or figure out a way \n",
    "# to pass a list of files to the read command. It's up to you\n",
    "\n",
    "with open (\"data/5c1dbe1d1e67d78e2797d611.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "facf0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sents(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    sentences = list(doc.sents)\n",
    "    return(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b25ae3",
   "metadata": {},
   "source": [
    "### Finding text within quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e6dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quotes(text):\n",
    "    quotes = re.findall(r' \"(.*?)\"', text)\n",
    "    return(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9211596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_sents = find_sents(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44e54193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Honestly, it feels like we're living our worst nightmare right now,\"]\n",
      "['It does say that in the letter,', 'I have no idea where that information came from because both Clark and I were there in the office with all of the workers from the orphanage.']\n",
      "['the Government of Canada has obligations under international conventions to ensure children are not abducted, bought or sold, or removed from their biological families without legal consent.']\n",
      "['in some cases, extra steps in the citizenship or immigration process may be needed to make sure the adoption meets all requirements of international adoption.']\n",
      "[\"We're not giving up, but it feels really overwhelming to think about what this means and what they're trying to do to us right now,\"]\n",
      "[\"I can't believe that this is our life, that this is our story.\"]\n"
     ]
    }
   ],
   "source": [
    "# note: this just prints the text in quotes. If you want to save it locally\n",
    "# to analyze how the 3 approaches are different, you need to run a command to save\n",
    "# for instance to a text file\n",
    "\n",
    "for sent in found_sents:\n",
    "    str_sent = str(sent)\n",
    "    found_quotes = get_quotes(str_sent)\n",
    "    if len(found_quotes) > 0:\n",
    "        print(found_quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8c6a71",
   "metadata": {},
   "source": [
    "## Approach 2: Using spaCy's Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92488d32",
   "metadata": {},
   "source": [
    "This approach is based on notebooks by Dr. W.J.B. Mattingly, http://spacy.pythonhumanities.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c740d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the stuff we'll need\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411eae45",
   "metadata": {},
   "source": [
    "## spaCy's Matcher\n",
    "This notebook relies on spaCy's Matcher (see Advanced NLP with spaCy, [chapter 2](https://course.spacy.io/en/chapter2)). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed7cac",
   "metadata": {},
   "source": [
    "## Finding quotes and speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "29bad1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a text file. Remember, you have to do 5\n",
    "with open (\"data/5c1dbe1d1e67d78e2797d611.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "with open (\"data/5c1dccbf1e67d78e279807d8.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text2 = f.read()\n",
    "with open (\"data/5c1de1661e67d78e27984d34.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text3 = f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "34f969ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When I first walk into his store, a fantastical comic book shop lodged discreetly in Kitchener’s Frederick Mall, I spot him from the corner of my eye, the gracious gatekeeper who invites visitors into a world of fantasy and makes their dreams come true. No, I’m not talking about Ricardo Montalban, who played that rugged emissary of wish-fulfilment, Mr. Roarke, on TV’s Fantasy Island with help from his sidekick, Tattoo. \n",
      " Alfonso Espinos, Andre Campbell, and Alexander Wise inside Studiocomix Press in Frederick Mall, Kitchene. Studiocomix Press is an indie comic-book publisher that will publish anything by anyone. ( Peter Lee / Waterloo Region Record ). \n",
      " I’m talking about Alfonso Espinos, who like Montalban was born in Mexico and made his way to North America to fulfil dreams of a different kind. “We dedicate ourselves solely to independent comic books and local creators,’’ says the 39-year-old founder of Studiocomix Press, which recently celebrated its first birthday. The operation is Waterloo Region’s sole indie comic-book store that is also a printer and publisher — possibly the only one in Canada (or the world). “If you want Marvel, you can go to another comic book shop.”. \n",
      " Article Continued Below. \n",
      " Forget superheroes. They’re represented, but for Espinos — whose store carries works by 200 indie comic-book artists — they’re the tip of the iceberg. “You’re talking about one genre only,” points out the laid-back Cambridge resident, who moved to Canada 15 years ago. “The vast majority of artists do not do superhero comics. There’s sci-fi, horror, children’s, Westerns …” Festooned with colourful indie comics of all styles, genres and levels of expertise, the store is an inspiring tribute to the art of the possible — an escapist retreat with an empowering subtext. “I’m a comic book creator myself,” notes Espinos, who launched his career as a teenager in Mexico and met the now-deceased Marvel guru Stan Lee three times. \n",
      " “I was on the other side 20 years ago. I understand what their needs are.” He’s being modest. To the people who seek his help creating and displaying their art, the ball-capped entrepreneur — whose clients include Mitch Markowitz from The Hilarious House of Frightenstein and the guy who played Joey Jeremiah on Degrassi Junior High — is less publisher than mentor, friend and overseer. \n",
      " Article Continued Below. \n",
      " “Every publisher rejected me,” says Cambridge cartoonist Andre Campbell, whose superhero in Starkeeper uses a wheelchair and is patterned after his own life. “They liked my stories, but not the art. They were looking for the DC Comics style.” Campbell has cerebral palsy, which creates physical challenges that make a computer critical for drawing his distinctive, visually arresting artwork. His universal message of diversity and inclusion? That comes directly from his brain. “In my experience, there hasn’t been a whole lot of representation of disabled characters in comics,” says the bow-tied maverick, noting that his disability doesn’t define who he is. “I wanted to emphasize that no matter who you are you can do anything.” In Espinos, he found a willing accomplice, a guy willing to nurture his vision without judgment. “Before I met Alfonso, I didn’t really have a lot of faith in the industry,” says Campbell, whose superhero was inspired, in part, by DC crime-fighter the Green Lantern. “Now I have tons.” His determination has paid off, with sales of 500 copies of his two comics turning the 29-year-old sensitivity trainer at Extend-A-Family into an inspiration for others with physical challenges. “They say, ‘Oh my God, you’re doing this? Maybe I can too!’ ” It’s not about scale or a guest spot on Jimmy Kimmel. None of Espinos’ clients are in it for the money. “Most places will not print anything less than 1,000 copies,” says Campbell’s partner, Jason Louth. The Studiocomix minimum is … “One!” says the affable proprietor. “No, two … (laughs) one goes on the shelf.” Never mind the sales figures. There is a particular satisfaction, insists 16-year-old Xander Wise, in seeing your vision through to completion, to know you’ve created a piece of art, no matter how many copies you sell. “It’s months and months of doing panels and fixing mistakes,” says the self-taught Cambridge resident, who sold 40 copies of his mystical war comic Forgotten Grunt: The Undead Soldier, inspired by the movies Platoon and Apocalypse Now. “But as soon as you do all that work and have that copy in your hands, you realize it’s all been worth it. There have been a few times where I was feeling unmotivated, but as soon as I saw how it turned out I was more than happy.” “If Alfonso wasn’t publishing local comics, I don’t think Xander would be doing what he’s doing,” says Wise’s dad, Darrin. For Espinos, who understands the challenges of ambition without unlimited financial backing, he’s simply filling a market niche. “You gotta start somewhere,” he says matter-of-factly. “Nobody starts out selling 50,000 copies. Every artist has a different definition of success.” Email: jrubinoff@therecord.com\n"
     ]
    }
   ],
   "source": [
    "# convert it to a spacy doc\n",
    "doc = nlp(text)\n",
    "doc2 = nlp(text2)\n",
    "doc3 = nlp(text3)\n",
    "\n",
    "#show the text\n",
    "#print(doc)\n",
    "print(doc2)\n",
    "#print(doc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749f943",
   "metadata": {},
   "source": [
    "### Finding proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "86fedc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of matches: 0\n"
     ]
    }
   ],
   "source": [
    "## Extract multi-word nouns \n",
    "## greedy = \"LONGEST\" will match as much as possible of the noun, in this case, do we want \"CTV News Friday\" or just Friday?\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_n = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern_n], greedy=\"LONGEST\")\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "#print (len(matches))\n",
    "#for match in matches[:10]:\n",
    "    #print (match, doc[match[1]:match[2]])\n",
    "\n",
    "# Dependency Parse: https://spacy.io/usage/visualizers\n",
    "# https://spacy.io/usage/linguistic-features#named-entities\n",
    "\n",
    "# spaCy matcher documentation: https://spacy.io/api/matcher\n",
    "\n",
    "\n",
    "#matchlist = []\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# pattern_z = [{\"TEXT\": \"said\", \"OP\": \"+\"}]\n",
    "# pattern_q = [{'TEXT': 'said'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '.'}]\n",
    "\n",
    "pattern_q = [\n",
    "    \n",
    "    #PROPN, said\n",
    "    [{\"POS\": \"PROPN\", \"OP\": \"+\"}, {'TEXT': 'said'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'IS_ALPHA': True, \"OP\": \"*\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'IS_ALPHA': True, \"OP\": \"*\"}, {'ORTH': \".\"}], \n",
    "    \n",
    "    #According to\n",
    "    [{\"TEXT\": 'According'}, {'IS_ALPHA': True, \"OP\": \"*\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {\"IS_ALPHA\": True, \"OP\": \"*\"}, {\"POS\": \"PART\", \"OP\": \"*\"}, {'IS_ALPHA': True, \"OP\": \"*\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {\"IS_ALPHA\": True, \"OP\": \"*\"}]\n",
    "    \n",
    "]\n",
    "\n",
    "matcher.add(\"INDIRECT QUOTES\", pattern_q, greedy=\"LONGEST\")\n",
    "doc = nlp(text2)\n",
    "matches = matcher(doc)\n",
    "print (\"amount of matches:\", len(matches))\n",
    "for match in matches[:10]:\n",
    "    #print(match)\n",
    "    print (match, doc[match[1]:match[2]])\n",
    "    #matchlist.append(doc[match[1]:match[2]])\n",
    "    \n",
    "\n",
    "# In this text, some indirect examples of quotes are According to [person],\n",
    "# IRCC has told, IRCC has stressed, Kim said, \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba7ee4",
   "metadata": {},
   "source": [
    "### Finding quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3f857916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(16432004385153140588, 115, 133) \"The fact that we are being accused right now of an unethical adoption is crazy.\"\n",
      "(16432004385153140588, 164, 174) \"It does say that in the letter,\"\n",
      "(16432004385153140588, 179, 209) \"I have no idea where that information came from because both Clark and I were there in the office with all of the workers from the orphanage.\"\n"
     ]
    }
   ],
   "source": [
    "# a simple pattern to extract things in single quotes\n",
    "# as with Approach 1, the for loop prints the results to the screen\n",
    "# you can try and save it to a file if you want to compare with Approach 1 and 3\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_q = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}]\n",
    "matcher.add(\"QUOTES\", [pattern_q], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:10]:\n",
    "    print (match, doc[match[1]:match[2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a9e0bd",
   "metadata": {},
   "source": [
    "## Approach 3: Implemented version\n",
    "This approach was implemented by colleagues at the [Australian Text Analytics Platform](https://www.atap.edu.au/) (ATAP). The approach is based on the [Gender Gap Tracker](https://github.com/sfu-discourse-lab/GenderGapTracker) done in the Discourse Processing Lab here at SFU. \n",
    "\n",
    "The first link below leads you to a binder where you can load your own files and download the output. If you prefer to do everything in your own notebook, you can download/clone the project and you'll see a notebook there (quote_extractor_notebook.ipynb)\n",
    "\n",
    "* [Binder link](https://github.com/Australian-Text-Analytics-Platform/quotation-tool/blob/workshop_01_20220908/README.md)\n",
    "* [Regular GitHub project](https://github.com/Australian-Text-Analytics-Platform/quotation-tool)\n",
    "\n",
    "Within the ATAP binder, upload 5 files from A1/data (the same you did for approaches 1 and 2), process them and download the results to your own computer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6115a0d8",
   "metadata": {},
   "source": [
    "## Your turn\n",
    "\n",
    "Check instructions on Canvas for what to do and what to submit. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925ebf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
